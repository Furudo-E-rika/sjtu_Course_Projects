{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "occasional-tennessee",
   "metadata": {
    "papermill": {
     "duration": 0.028099,
     "end_time": "2021-06-17T06:36:25.544592",
     "exception": false,
     "start_time": "2021-06-17T06:36:25.516493",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EE359-Coursework 4  Streaming Algorithm\n",
    "Existing codes in this file are just hints. You can modify these codes as you want"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "possible-province",
   "metadata": {
    "papermill": {
     "duration": 0.026092,
     "end_time": "2021-06-17T06:36:25.597706",
     "exception": false,
     "start_time": "2021-06-17T06:36:25.571614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Task1ï¼šDGIM**\n",
    "\n",
    "DGIM is an efficient algorithm in processing large streams. When it's infeasible to store the flowing binary stream, DGIM can estimate the number of 1-bits in the window. In this coding, you're given the stream_data_dgim.txt (binary stream), and you need to implement the DGIM algorithm to count the number of 1-bits. Write code below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "interior-newsletter",
   "metadata": {
    "papermill": {
     "duration": 0.026338,
     "end_time": "2021-06-17T06:36:25.650472",
     "exception": false,
     "start_time": "2021-06-17T06:36:25.624134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Set the window size to 1000, and count the number of 1-bits in the current window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "activated-sound",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:25.717213Z",
     "iopub.status.busy": "2021-06-17T06:36:25.716613Z",
     "iopub.status.idle": "2021-06-17T06:36:25.720949Z",
     "shell.execute_reply": "2021-06-17T06:36:25.720153Z",
     "shell.execute_reply.started": "2021-06-02T12:01:27.189182Z"
    },
    "papermill": {
     "duration": 0.042437,
     "end_time": "2021-06-17T06:36:25.721129",
     "exception": false,
     "start_time": "2021-06-17T06:36:25.678692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Count (last 1000): 316\n",
      "Running Time: 6.818771362304688e-05\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "class DGIM:\n",
    "    def __init__(self, filepath, windowsize, maxtime = None):\n",
    "        self.fileHandler = open(filepath, 'r')\n",
    "        self.windowSize = windowsize\n",
    "        self.buckets = defaultdict(list)\n",
    "        self.timeMod = maxtime if maxtime else windowsize << 2\n",
    "        self.timestamp = 0\n",
    "    \n",
    "    def update(self):\n",
    "        keys = sorted(self.buckets.keys(), reverse=True)\n",
    "        for key in keys:\n",
    "            if len(self.buckets[key]) > 0:\n",
    "                if min(self.buckets[key]) < self.timestamp - self.windowSize:\n",
    "                    self.buckets[key].remove(min(self.buckets[key]))\n",
    "                    break\n",
    "\n",
    "        \n",
    "        self.merge_buckets()\n",
    "\n",
    "    def merge_buckets(self):\n",
    "        i = 1\n",
    "        while i < self.timeMod:\n",
    "            if len(self.buckets[i]) > 2:\n",
    "                min_1 = min(self.buckets[i])\n",
    "                self.buckets[i].remove(min_1)\n",
    "                min_2 = min(self.buckets[i])\n",
    "                self.buckets[i].remove(min_2)\n",
    "                self.buckets[i*2].append(min(min_1, min_2))\n",
    "            i *= 2\n",
    "    \n",
    "    def run(self):\n",
    "        f = self.fileHandler\n",
    "        x = f.read(2).strip()\n",
    "        while x:\n",
    "            if x == '1':\n",
    "                self.buckets[1].append(self.timestamp)\n",
    "                self.update()\n",
    "            self.timestamp = (self.timestamp + 1) % self.timeMod\n",
    "            \n",
    "            x = f.read(2).strip()\n",
    "    \n",
    "    def count(self, start):\n",
    "        total = 0\n",
    "        last_bucket_size = 0 \n",
    "\n",
    "        for key in sorted(self.buckets.keys()):\n",
    "            \n",
    "            if len(self.buckets[key]) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                last_bucket_size = 0\n",
    "\n",
    "            for _stp in self.buckets[key]:\n",
    "\n",
    "                if _stp <= self.timestamp - start:\n",
    "                    continue\n",
    "                total += key\n",
    "                last_bucket_size += key\n",
    "\n",
    "        return total - last_bucket_size // 2\n",
    "\n",
    "\n",
    "Solver = DGIM(filepath='./stream_data_dgim.txt', windowsize=1000, maxtime=40001)\n",
    "Solver.run()\n",
    "start_time = time.time()\n",
    "predictedCount= Solver.count(start=1000)\n",
    "end_time = time.time()\n",
    "pre_running_time = end_time - start_time\n",
    "print('Predicted Count (last 1000):', predictedCount)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "unavailable-avatar",
   "metadata": {
    "papermill": {
     "duration": 0.026729,
     "end_time": "2021-06-17T06:36:25.942562",
     "exception": false,
     "start_time": "2021-06-17T06:36:25.915833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. With the window size 1000, count the number of 1-bits in the last 500 and 200 bits of the bitstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "northern-serum",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:26.000387Z",
     "iopub.status.busy": "2021-06-17T06:36:25.999522Z",
     "iopub.status.idle": "2021-06-17T06:36:26.005633Z",
     "shell.execute_reply": "2021-06-17T06:36:26.004945Z",
     "shell.execute_reply.started": "2021-06-02T12:02:22.109405Z"
    },
    "papermill": {
     "duration": 0.036054,
     "end_time": "2021-06-17T06:36:26.005766",
     "exception": false,
     "start_time": "2021-06-17T06:36:25.969712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Count (last 500): 188\n",
      "Predicted Count (last 200): 60\n"
     ]
    }
   ],
   "source": [
    "# code here\n",
    "print('Predicted Count (last 500):', Solver.count(start=500))\n",
    "\n",
    "print('Predicted Count (last 200):', Solver.count(start=200))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "advisory-destruction",
   "metadata": {
    "papermill": {
     "duration": 0.027634,
     "end_time": "2021-06-17T06:36:26.061269",
     "exception": false,
     "start_time": "2021-06-17T06:36:26.033635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Write a function that accurately counts the number of 1-bits in the current window. Caculate the accuracy of your own DGIM algorithm and compare the running time difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "excited-firmware",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:26.123676Z",
     "iopub.status.busy": "2021-06-17T06:36:26.122857Z",
     "iopub.status.idle": "2021-06-17T06:36:26.171342Z",
     "shell.execute_reply": "2021-06-17T06:36:26.170504Z",
     "shell.execute_reply.started": "2021-06-02T12:02:34.036051Z"
    },
    "papermill": {
     "duration": 0.082241,
     "end_time": "2021-06-17T06:36:26.171504",
     "exception": false,
     "start_time": "2021-06-17T06:36:26.089263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate Count (last 1000): 391\n",
      "Accurancy: 0.8081841432225064\n",
      "Running time of DGIM is 0.06818771362304688 ms. Running time of accurately counting is 13.064384460449219 ms\n"
     ]
    }
   ],
   "source": [
    "# Your code here, you can add cells if necessary\n",
    "import numpy as np\n",
    "import time\n",
    "def accurateCountTask1(filepath='./stream_data_dgim.txt', window_size=1000):\n",
    "    start_time = time.time()\n",
    "    stream = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        x = f.read(2).strip()\n",
    "        while x:\n",
    "            stream.append(int(x))\n",
    "            x = f.read(2).strip()\n",
    "    count = sum(stream[-1 * window_size:])\n",
    "    end_time = time.time()\n",
    "    return count, end_time - start_time\n",
    "\n",
    "accurateCount, acc_running_time = accurateCountTask1()\n",
    "    \n",
    "print('Accurate Count (last 1000):', accurateCount)\n",
    "print('Accurancy:', 1 - abs(predictedCount - accurateCount) / accurateCount)\n",
    "print(f'Running time of DGIM is {1000 * pre_running_time} ms. Running time of accurately counting is {1000* acc_running_time} ms')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acting-western",
   "metadata": {
    "papermill": {
     "duration": 0.027707,
     "end_time": "2021-06-17T06:36:26.227410",
     "exception": false,
     "start_time": "2021-06-17T06:36:26.199703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Task2: Bloom Filter**\n",
    "\n",
    "A Bloom filter is a space-efficient probabilistic data structure. Here the task is to implement a bloom filter by yourself. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "colored-blocking",
   "metadata": {
    "papermill": {
     "duration": 0.027519,
     "end_time": "2021-06-17T06:36:26.282797",
     "exception": false,
     "start_time": "2021-06-17T06:36:26.255278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data loading:\n",
    "\n",
    "From the NLTK (Natural Language ToolKit) library, we import a large list of English dictionary words, commonly used by the very first spell-checking programs in Unix-like operating systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "magnetic-casino",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:26.343667Z",
     "iopub.status.busy": "2021-06-17T06:36:26.343062Z",
     "iopub.status.idle": "2021-06-17T06:36:28.084580Z",
     "shell.execute_reply": "2021-06-17T06:36:28.084175Z",
     "shell.execute_reply.started": "2021-06-17T06:35:19.307980Z"
    },
    "papermill": {
     "duration": 1.773889,
     "end_time": "2021-06-17T06:36:28.084700",
     "exception": false,
     "start_time": "2021-06-17T06:36:26.310811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words\n",
    "# nltk.download('words')\n",
    "word_list = words.words()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "involved-princess",
   "metadata": {
    "papermill": {
     "duration": 0.017573,
     "end_time": "2021-06-17T06:36:28.120867",
     "exception": false,
     "start_time": "2021-06-17T06:36:28.103294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then we load another dataset from the NLTK Corpora collection: movie_reviews.\n",
    "\n",
    "The movie reviews are categorized between positive and negative, so we construct a list of words (usually called bag of words) for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pretty-disaster",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:28.175929Z",
     "iopub.status.busy": "2021-06-17T06:36:28.173349Z",
     "iopub.status.idle": "2021-06-17T06:36:31.060114Z",
     "shell.execute_reply": "2021-06-17T06:36:31.059551Z",
     "shell.execute_reply.started": "2021-06-17T06:35:27.493476Z"
    },
    "papermill": {
     "duration": 2.921382,
     "end_time": "2021-06-17T06:36:31.060232",
     "exception": false,
     "start_time": "2021-06-17T06:36:28.138850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nltk.download('movie_reviews')\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "neg_reviews = []\n",
    "pos_reviews = []\n",
    "\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "  neg_reviews.extend(movie_reviews.words(fileid))\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "  pos_reviews.extend(movie_reviews.words(fileid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "proper-canada",
   "metadata": {
    "papermill": {
     "duration": 0.017491,
     "end_time": "2021-06-17T06:36:31.096095",
     "exception": false,
     "start_time": "2021-06-17T06:36:31.078604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we get a data stream (word_list) and 2 query lists (neg_reviews and pos_reviews)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dense-sleep",
   "metadata": {
    "papermill": {
     "duration": 0.017858,
     "end_time": "2021-06-17T06:36:31.131752",
     "exception": false,
     "start_time": "2021-06-17T06:36:31.113894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Write a function that accurately determines whether each word in neg_reviews and pos_reviews belongs to word_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "worse-service",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:31.173903Z",
     "iopub.status.busy": "2021-06-17T06:36:31.173444Z",
     "iopub.status.idle": "2021-06-17T06:36:31.175860Z",
     "shell.execute_reply": "2021-06-17T06:36:31.175408Z",
     "shell.execute_reply.started": "2021-06-17T06:35:33.558906Z"
    },
    "papermill": {
     "duration": 0.026247,
     "end_time": "2021-06-17T06:36:31.175974",
     "exception": false,
     "start_time": "2021-06-17T06:36:31.149727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def linear_search(word_list, target_word):\n",
    "    ## According to the annotation in the next block, I implement the binary search function instead of linear search.\n",
    "    start = 0\n",
    "    end = len(word_list) - 1\n",
    "    mid = 0\n",
    "    while start <= end:\n",
    "        mid = (start + end) // 2\n",
    "    \n",
    "        if word_list[mid] < target_word:\n",
    "            start = mid + 1\n",
    "\n",
    "        elif word_list[mid] > target_word:\n",
    "            end = mid - 1\n",
    "\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "executive-marketplace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:31.219426Z",
     "iopub.status.busy": "2021-06-17T06:36:31.218542Z",
     "iopub.status.idle": "2021-06-17T06:36:33.645616Z",
     "shell.execute_reply": "2021-06-17T06:36:33.645097Z",
     "shell.execute_reply.started": "2021-06-17T06:35:35.345876Z"
    },
    "papermill": {
     "duration": 2.451173,
     "end_time": "2021-06-17T06:36:33.645747",
     "exception": false,
     "start_time": "2021-06-17T06:36:31.194574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Time: 5.356951951980591\n"
     ]
    }
   ],
   "source": [
    "# Binary search\n",
    "neg_flag_b = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_flag_b = np.zeros(len(pos_reviews), dtype=bool)\n",
    "# to store the accurate result\n",
    "\n",
    "t = time.time()\n",
    "sorted_word_list = sorted(word_list)\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_flag_b[i] = linear_search(sorted_word_list, neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_flag_b[i] = linear_search(sorted_word_list, pos_word)\n",
    "print(\"Search Time:\", time.time() - t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "moral-diamond",
   "metadata": {
    "papermill": {
     "duration": 0.019059,
     "end_time": "2021-06-17T06:36:33.683932",
     "exception": false,
     "start_time": "2021-06-17T06:36:33.664873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ### 2. Implement the bloom filter by yourself and add all words in word_list in your bloom filter. Compare the running time difference between exact search (Task2 Question1) and multiple hash computations in a Bloom filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "brief-helping",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:33.723893Z",
     "iopub.status.busy": "2021-06-17T06:36:33.723412Z",
     "iopub.status.idle": "2021-06-17T06:36:33.730433Z",
     "shell.execute_reply": "2021-06-17T06:36:33.730806Z",
     "shell.execute_reply.started": "2021-06-17T06:35:40.935475Z"
    },
    "papermill": {
     "duration": 0.028398,
     "end_time": "2021-06-17T06:36:33.730935",
     "exception": false,
     "start_time": "2021-06-17T06:36:33.702537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here, you can add cells if necessary\n",
    "import hashlib\n",
    "\n",
    "class BloomFilter:\n",
    "    def __init__(self, m, k):\n",
    "        self.m = int(m)\n",
    "        self.k = int(k)\n",
    "        self.table = np.zeros((self.m), dtype = bool)\n",
    "    def add(self, item):\n",
    "        hash1 = hashlib.sha256()\n",
    "        hash1.update(item.encode())\n",
    "        hash1 = int(hash1.hexdigest(), 16) % self.m\n",
    "        hash2 = hashlib.md5()\n",
    "        hash2.update(item.encode())\n",
    "        hash2 = int(hash2.hexdigest(), 16) % self.m\n",
    "        h = hash1\n",
    "        for i in range(self.k):\n",
    "            self.table[(h + i * hash2) % self.m] = True\n",
    "    def check(self, item):\n",
    "        hash1 = hashlib.sha256()\n",
    "        hash1.update(item.encode())\n",
    "        hash1 = int(hash1.hexdigest(), 16) % self.m\n",
    "        hash2 = hashlib.md5()\n",
    "        hash2.update(item.encode())\n",
    "        hash2 = int(hash2.hexdigest(), 16) % self.m\n",
    "        h = hash1\n",
    "        for i in range(self.k):\n",
    "            if self.table[(h + i * hash2) % self.m] == False:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "casual-slope",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T06:36:33.770924Z",
     "iopub.status.busy": "2021-06-17T06:36:33.770439Z",
     "iopub.status.idle": "2021-06-17T06:36:40.521347Z",
     "shell.execute_reply": "2021-06-17T06:36:40.521746Z",
     "shell.execute_reply.started": "2021-06-17T06:35:43.948830Z"
    },
    "papermill": {
     "duration": 6.772232,
     "end_time": "2021-06-17T06:36:40.521877",
     "exception": false,
     "start_time": "2021-06-17T06:36:33.749645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "m = 1e7, k = 4\n",
      "Bloom Filter Time: 20.547614336013794\n",
      "Accuracy:\n",
      "neg: 751255 / 751256\n",
      "pos: 832564 / 832564\n",
      "False Positive Rate (neg): 4.75606160050985e-06\n",
      "False Positive Rate (pos): 0.0\n"
     ]
    }
   ],
   "source": [
    "bf = BloomFilter(1e7, 4)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e7, k = 4\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "capable-crossing",
   "metadata": {
    "papermill": {
     "duration": 0.018734,
     "end_time": "2021-06-17T07:46:13.277011",
     "exception": false,
     "start_time": "2021-06-17T07:46:13.258277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Use different bit array length â€˜mâ€™ and number of hash functions â€˜kâ€™ to implement the bloom filter algorithm. Then compare the impact of different m and k on the false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a58dfbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "m = 1e6, k = 4\n",
      "Bloom Filter Time: 19.902321577072144\n",
      "Accuracy:\n",
      "neg: 695661 / 751256\n",
      "pos: 767160 / 832564\n",
      "False Positive Rate (neg): 0.2644132446803451\n",
      "False Positive Rate (pos): 0.28138498339327817\n",
      "********************\n",
      "m = 1e5, k = 4\n",
      "Bloom Filter Time: 19.596858978271484\n",
      "Accuracy:\n",
      "neg: 541011 / 751256\n",
      "pos: 600144 / 832564\n",
      "False Positive Rate (neg): 0.9999381711991934\n",
      "False Positive Rate (pos): 0.9999311638472526\n",
      "********************\n",
      "m = 1e4, k = 4\n",
      "Bloom Filter Time: 19.76619577407837\n",
      "Accuracy:\n",
      "neg: 540998 / 751256\n",
      "pos: 600128 / 832564\n",
      "False Positive Rate (neg): 1.0\n",
      "False Positive Rate (pos): 1.0\n"
     ]
    }
   ],
   "source": [
    "##########################################   m = 1e6, k = 4   ########################################## \n",
    "\n",
    "bf = BloomFilter(1e6, 4)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e6, k = 4\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")\n",
    "\n",
    "##########################################   m = 1e5, k = 4   ########################################## \n",
    "bf = BloomFilter(1e5, 4)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "    \n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e5, k = 4\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")\n",
    "\n",
    "##########################################   m = 1e4, k = 4   ########################################## \n",
    "bf = BloomFilter(1e4, 4)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e4, k = 4\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4967bc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "m = 1e7, k = 10\n",
      "Bloom Filter Time: 27.79302144050598\n",
      "Accuracy:\n",
      "neg: 751256 / 751256\n",
      "pos: 832564 / 832564\n",
      "False Positive Rate (neg): 0.0\n",
      "False Positive Rate (pos): 0.0\n",
      "********************\n",
      "m = 1e7, k = 5\n",
      "Bloom Filter Time: 21.780128002166748\n",
      "Accuracy:\n",
      "neg: 751256 / 751256\n",
      "pos: 832564 / 832564\n",
      "False Positive Rate (neg): 0.0\n",
      "False Positive Rate (pos): 0.0\n",
      "********************\n",
      "m = 1e7, k = 3\n",
      "Bloom Filter Time: 20.07935667037964\n",
      "Accuracy:\n",
      "neg: 751247 / 751256\n",
      "pos: 832543 / 832564\n",
      "False Positive Rate (neg): 4.280455440458865e-05\n",
      "False Positive Rate (pos): 9.034745048099262e-05\n",
      "********************\n",
      "m = 1e7, k = 2\n",
      "Bloom Filter Time: 18.719287872314453\n",
      "Accuracy:\n",
      "neg: 751176 / 751256\n",
      "pos: 832456 / 832564\n",
      "False Positive Rate (neg): 0.000380484928040788\n",
      "False Positive Rate (pos): 0.0004646440310451049\n",
      "********************\n",
      "m = 1e7, k = 1\n",
      "Bloom Filter Time: 16.598642826080322\n",
      "Accuracy:\n",
      "neg: 747688 / 751256\n",
      "pos: 828475 / 832564\n",
      "False Positive Rate (neg): 0.016969627790619144\n",
      "False Positive Rate (pos): 0.017591939286513276\n"
     ]
    }
   ],
   "source": [
    "##########################################   m = 1e7, k = 10   ########################################## \n",
    "bf = BloomFilter(1e7, 10)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e7, k = 10\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")\n",
    "\n",
    "##########################################   m = 1e7, k = 5   ########################################## \n",
    "bf = BloomFilter(1e7, 5)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e7, k = 5\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")\n",
    "\n",
    "##########################################   m = 1e7, k = 3   ########################################## \n",
    "bf = BloomFilter(1e7, 3)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e7, k = 3\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")\n",
    "\n",
    "##########################################   m = 1e7, k = 2   ########################################## \n",
    "\n",
    "bf = BloomFilter(1e7, 2)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_TN = sum(neg_bf[i] == False and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_TN = sum(pos_bf[i] == False and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e7, k = 2\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / (neg_FP + neg_TN)}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / (pos_FP + pos_TN)}\")\n",
    "\n",
    "##########################################   m = 1e7, k = 1   ########################################## \n",
    "\n",
    "bf = BloomFilter(1e7, 1)\n",
    "neg_bf = np.zeros(len(neg_reviews), dtype=bool)\n",
    "pos_bf = np.zeros(len(pos_reviews), dtype=bool)\n",
    "n = neg_bf.shape[0] + pos_bf.shape[0]\n",
    "t = time.time()\n",
    "for word in word_list:\n",
    "    bf.add(word)\n",
    "\n",
    "for i, neg_word in enumerate(neg_reviews):\n",
    "    neg_bf[i] = bf.check(neg_word)\n",
    "for i, pos_word in enumerate(pos_reviews):\n",
    "    pos_bf[i] = bf.check(pos_word)\n",
    "\n",
    "neg_FP = sum(neg_bf[i] == True and neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "neg_N = sum(neg_flag_b[i] == False for i in range(len(neg_reviews)))\n",
    "pos_FP = sum(pos_bf[i] == True and pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "pos_N = sum(pos_flag_b[i] == False for i in range(len(pos_reviews)))\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"m = 1e7, k = 1\")\n",
    "print(\"Bloom Filter Time:\", time.time()-t)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"neg: {(neg_bf == neg_flag_b).sum()} / {neg_bf.shape[0]}\")\n",
    "print(f\"pos: {(pos_bf == pos_flag_b).sum()} / {pos_bf.shape[0]}\")\n",
    "print(f\"False Positive Rate (neg): {neg_FP / neg_N}\")\n",
    "print(f\"False Positive Rate (pos): {pos_FP / pos_N}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "descending-hudson",
   "metadata": {
    "papermill": {
     "duration": 0.02154,
     "end_time": "2021-06-17T07:47:25.182648",
     "exception": false,
     "start_time": "2021-06-17T07:47:25.161108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Task3: Count-Min sketch**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "limited-minute",
   "metadata": {
    "papermill": {
     "duration": 0.021336,
     "end_time": "2021-06-17T07:47:25.225512",
     "exception": false,
     "start_time": "2021-06-17T07:47:25.204176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In computing, the countâ€“min sketch (CM sketch) is a probabilistic data structure that serves as a frequency table of events in a stream of data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fancy-secretary",
   "metadata": {
    "papermill": {
     "duration": 0.021627,
     "end_time": "2021-06-17T07:47:25.269245",
     "exception": false,
     "start_time": "2021-06-17T07:47:25.247618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we use the query stream (neg_reviews or pos_reviews) from task 2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "documentary-broad",
   "metadata": {
    "papermill": {
     "duration": 0.021543,
     "end_time": "2021-06-17T07:47:25.312815",
     "exception": false,
     "start_time": "2021-06-17T07:47:25.291272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Write a function that accurately counts the occurrence times of each word in neg_reviews or pos_reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "supported-symbol",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T07:47:25.376670Z",
     "iopub.status.busy": "2021-06-17T07:47:25.371449Z",
     "iopub.status.idle": "2021-06-17T07:47:25.494432Z",
     "shell.execute_reply": "2021-06-17T07:47:25.493992Z"
    },
    "papermill": {
     "duration": 0.159072,
     "end_time": "2021-06-17T07:47:25.494543",
     "exception": false,
     "start_time": "2021-06-17T07:47:25.335471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here, you can add cells if necessary\n",
    "\n",
    "def accCount(words):\n",
    "    count_dic = {}\n",
    "    for word in words:\n",
    "        if word not in count_dic:\n",
    "            count_dic[word] = 1\n",
    "        else:\n",
    "            count_dic[word] += 1\n",
    "    return count_dic\n",
    "\n",
    "neg_accCount = accCount(neg_reviews)\n",
    "pos_accCount = accCount(pos_reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "painted-homeless",
   "metadata": {
    "papermill": {
     "duration": 0.021832,
     "end_time": "2021-06-17T07:47:25.538373",
     "exception": false,
     "start_time": "2021-06-17T07:47:25.516541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Implement the Count-Min sketch by yourself. Set different width w and depth d of the internal data structure of CM-Sketch. Compare the influence of different w and d on the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "hindu-profit",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T07:47:25.585156Z",
     "iopub.status.busy": "2021-06-17T07:47:25.584646Z",
     "iopub.status.idle": "2021-06-17T07:47:25.593097Z",
     "shell.execute_reply": "2021-06-17T07:47:25.593467Z"
    },
    "papermill": {
     "duration": 0.032952,
     "end_time": "2021-06-17T07:47:25.593608",
     "exception": false,
     "start_time": "2021-06-17T07:47:25.560656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here, you can add cells if necessary\n",
    "class CountMin:\n",
    "    def __init__(self, w, d):\n",
    "        self.w = int(w)\n",
    "        self.d = int(d)\n",
    "        self.table=np.zeros((self.d, self.w), dtype=int)\n",
    "        \n",
    "    def add(self, item):\n",
    "        hash1 = hashlib.sha256()\n",
    "        hash1.update(item.encode())\n",
    "        hash1 = int(hash1.hexdigest(), 16) % self.w\n",
    "        hash2 = hashlib.md5()\n",
    "        hash2.update(item.encode())\n",
    "        hash2 = int(hash2.hexdigest(), 16) % self.w\n",
    "        h = hash1\n",
    "        for i in range(self.d):\n",
    "            self.table[i, (h + i * hash2) % self.w] += 1\n",
    "\n",
    "    def count(self, item):\n",
    "        hash1 = hashlib.sha256()\n",
    "        hash1.update(item.encode())\n",
    "        hash1 = int(hash1.hexdigest(), 16) % self.w\n",
    "        hash2 = hashlib.md5()\n",
    "        hash2.update(item.encode())\n",
    "        hash2 = int(hash2.hexdigest(), 16) % self.w\n",
    "        h = hash1\n",
    "        return min(self.table[i, (h + i * hash2) % self.w] for i in range(self.d))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5ffedf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "w = 1e7, d = 4\n",
      "Mean Absolute Error: 0 / 751256\n",
      "********************\n",
      "w = 1e6, d = 4\n",
      "Mean Absolute Error: 0 / 751256\n",
      "\n",
      "********************\n",
      "w = 1e5, d = 4\n",
      "Mean Absolute Error: 137 / 751256\n",
      "\n",
      "********************\n",
      "w = 1e4, d = 4\n",
      "Mean Absolute Error: 104797 / 751256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## define the error computing function\n",
    "def mean_absolute_error(actual, predicted):\n",
    "    total_error = 0.0\n",
    "    count = 0\n",
    "    for key in actual.keys():\n",
    "        if key in predicted:\n",
    "            total_error += abs(actual[key] - predicted[key])\n",
    "        else:\n",
    "            total_error += actual[key]\n",
    "        count += actual[key]\n",
    "\n",
    "    for key in predicted.keys():\n",
    "        if key not in actual:\n",
    "            total_error += predicted[key]\n",
    "\n",
    "    return int(total_error), count\n",
    "\n",
    "\n",
    "CM_Sketch = CountMin(w=1e7, d=4)\n",
    "neg_CMCount = {}\n",
    "\n",
    "for word in neg_reviews:\n",
    "    CM_Sketch.add(word)\n",
    "\n",
    "for neg_word in neg_reviews:\n",
    "    neg_CMCount[neg_word] = CM_Sketch.count(neg_word)\n",
    "\n",
    "total_error, count = mean_absolute_error(neg_accCount, neg_CMCount)\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"w = 1e7, d = 4\")\n",
    "print(\"Mean Absolute Error: {} / {}\\n\".format(total_error, count))\n",
    "\n",
    "CM_Sketch = CountMin(w=1e6, d=4)\n",
    "neg_CMCount = {}\n",
    "\n",
    "for word in neg_reviews:\n",
    "    CM_Sketch.add(word)\n",
    "\n",
    "for neg_word in neg_reviews:\n",
    "    neg_CMCount[neg_word] = CM_Sketch.count(neg_word)\n",
    "\n",
    "total_error, count = mean_absolute_error(neg_accCount, neg_CMCount)\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"w = 1e6, d = 4\")\n",
    "print(\"Mean Absolute Error: {} / {}\\n\".format(total_error, count))\n",
    "\n",
    "CM_Sketch = CountMin(w=1e5, d=4)\n",
    "neg_CMCount = {}\n",
    "\n",
    "for word in neg_reviews:\n",
    "    CM_Sketch.add(word)\n",
    "\n",
    "for neg_word in neg_reviews:\n",
    "    neg_CMCount[neg_word] = CM_Sketch.count(neg_word)\n",
    "\n",
    "total_error, count = mean_absolute_error(neg_accCount, neg_CMCount)\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"w = 1e5, d = 4\")\n",
    "print(\"Mean Absolute Error: {} / {}\\n\".format(total_error, count))\n",
    "\n",
    "CM_Sketch = CountMin(w=1e4, d=4)\n",
    "neg_CMCount = {}\n",
    "\n",
    "for word in neg_reviews:\n",
    "    CM_Sketch.add(word)\n",
    "\n",
    "for neg_word in neg_reviews:\n",
    "    neg_CMCount[neg_word] = CM_Sketch.count(neg_word)\n",
    "\n",
    "total_error, count = mean_absolute_error(neg_accCount, neg_CMCount)\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"w = 1e4, d = 4\")\n",
    "print(\"Mean Absolute Error: {} / {}\\n\".format(total_error, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b59958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "w = 1e7, d = 3\n",
      "Mean Absolute Error: 0 / 751256\n",
      "\n",
      "********************\n",
      "w = 1e7, d = 2\n",
      "Mean Absolute Error: 0 / 751256\n",
      "\n",
      "********************\n",
      "w = 1e7, d = 1\n",
      "Mean Absolute Error: 719 / 751256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CM_Sketch = CountMin(w=1e7, d=3)\n",
    "neg_CMCount = {}\n",
    "\n",
    "for word in neg_reviews:\n",
    "    CM_Sketch.add(word)\n",
    "\n",
    "for neg_word in neg_reviews:\n",
    "    neg_CMCount[neg_word] = CM_Sketch.count(neg_word)\n",
    "\n",
    "total_error, count = mean_absolute_error(neg_accCount, neg_CMCount)\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"w = 1e7, d = 3\")\n",
    "print(\"Mean Absolute Error: {} / {}\\n\".format(total_error, count))\n",
    "\n",
    "CM_Sketch = CountMin(w=1e7, d=2)\n",
    "neg_CMCount = {}\n",
    "\n",
    "for word in neg_reviews:\n",
    "    CM_Sketch.add(word)\n",
    "\n",
    "for neg_word in neg_reviews:\n",
    "    neg_CMCount[neg_word] = CM_Sketch.count(neg_word)\n",
    "\n",
    "total_error, count = mean_absolute_error(neg_accCount, neg_CMCount)\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"w = 1e7, d = 2\")\n",
    "print(\"Mean Absolute Error: {} / {}\\n\".format(total_error, count))\n",
    "\n",
    "CM_Sketch = CountMin(w=1e7, d=1)\n",
    "neg_CMCount = {}\n",
    "\n",
    "for word in neg_reviews:\n",
    "    CM_Sketch.add(word)\n",
    "\n",
    "for neg_word in neg_reviews:\n",
    "    neg_CMCount[neg_word] = CM_Sketch.count(neg_word)\n",
    "\n",
    "total_error, count = mean_absolute_error(neg_accCount, neg_CMCount)\n",
    "\n",
    "print(\"*\" * 20)\n",
    "print(\"w = 1e7, d = 1\")\n",
    "print(\"Mean Absolute Error: {} / {}\\n\".format(total_error, count))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4615.162878,
   "end_time": "2021-06-17T07:53:15.335565",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-17T06:36:20.172687",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
